{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26e94cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a dataBatch (iterable of [image_batch, label_batch]) \n",
    "# into a tuple of two lists: one list of image batches, another of corresponding label batches.\n",
    "def from_DataBatch_to_list(dataBatch):\n",
    "  val_dataset2 = []  # list to collect image batches\n",
    "  val_dataset2_gt = []  # list to collect ground truth batches\n",
    "  i = 0  # index counter for elements within batch (0: images, 1: labels)\n",
    "\n",
    "  # Iterate over each batch in the provided dataBatch\n",
    "  for batch in dataBatch:\n",
    "    # Each batch is expected to be a sequence where index 0 is images and index 1 is labels\n",
    "    for i in range(len(batch)):\n",
    "      if i == 0:\n",
    "        val_dataset2.append(batch[i])  # append image batch\n",
    "      if i == 1:\n",
    "        val_dataset2_gt.append(batch[i])  # append label batch\n",
    "    \n",
    "  # Return a tuple (images_list, labels_list)\n",
    "  return (val_dataset2, val_dataset2_gt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21359cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def topk_accuracy(model, k, validation_tuple, device=None):\n",
    "    \"\"\"\n",
    "    Compute Top-K accuracy for a PyTorch model over a validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained PyTorch model.\n",
    "        k (int): Number of top predictions to consider for accuracy.\n",
    "        validation_tuple (tuple): A tuple (val_data, val_labels), where\n",
    "            - val_data is a list of input batches (torch.Tensor) of shape [B, C, H, W]\n",
    "            - val_labels is a list of corresponding label batches, either as class indices [B]\n",
    "        device (torch.device, optional): Device to run inference on. If None, uses CUDA if available.\n",
    "\n",
    "    return:\n",
    "        float: Top-K accuracy over the entire validation set.\n",
    "    \"\"\"\n",
    "    # Unpack validation data and labels\n",
    "    val_data, val_labels = validation_tuple\n",
    "\n",
    "    # Select device: use GPU if available and not specified\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move model to device and set to evaluation mode\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0  # Counter for correctly predicted samples\n",
    "    total = 0    # Counter for total samples\n",
    "\n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        # Iterate over batches of inputs and labels\n",
    "        for x_batch, y_batch in zip(val_data, val_labels):\n",
    "            # Move batch to the selected device\n",
    "            x_batch = x_batch.to(device)\n",
    "            y_batch = y_batch.to(device)\n",
    "\n",
    "            # Forward pass: obtain raw logits of shape [B, num_classes]\n",
    "            outputs = model(x_batch)\n",
    "\n",
    "            # Get the indices of the top-k predictions for each sample [B, k]\n",
    "            topk_inds = outputs.topk(k, dim=1).indices\n",
    "\n",
    "            # If labels are one-hot encoded, convert to class indices\n",
    "            if y_batch.dim() > 1:\n",
    "                y_true = y_batch.argmax(dim=1)\n",
    "            else:\n",
    "                y_true = y_batch  # Already class indices\n",
    "\n",
    "            # Compare true labels against top-k predictions: [B, k] boolean tensor\n",
    "            matches = topk_inds.eq(y_true.unsqueeze(1))\n",
    "\n",
    "            # Count samples where the true label is among the top-k predictions\n",
    "            correct += matches.any(dim=1).sum().item()\n",
    "            total += x_batch.size(0)\n",
    "\n",
    "    # Return the ratio of correct predictions\n",
    "    return correct / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed6152e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def confusion_matrix(model, failure_types, validation_tuple, thresholds, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device).eval()\n",
    "    \n",
    "    val_batches, label_batches = validation_tuple\n",
    "    C = len(failure_types)\n",
    "    defect_classes = C - 1  # 'none' 인덱스\n",
    "    \n",
    "    all_true = []\n",
    "    all_pred = []\n",
    "    all_prob = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in zip(val_batches, label_batches):\n",
    "            x = x_batch\n",
    "            # --- 입력 차원 보정 ---\n",
    "            # 3D: (H, W, C) → (1, C, H, W)\n",
    "            if isinstance(x, torch.Tensor) and x.dim() == 3:\n",
    "                if x.shape[-1] == 3:\n",
    "                    x = x.permute(2, 0, 1).contiguous()\n",
    "                x = x.unsqueeze(0)\n",
    "            # 4D NHWC: (B, H, W, C) → (B, C, H, W)\n",
    "            elif isinstance(x, torch.Tensor) and x.dim() == 4 and x.shape[-1] == 3:\n",
    "                x = x.permute(0, 3, 1, 2).contiguous()\n",
    "            \n",
    "            x = x.to(device).float()\n",
    "            logits = model(x)                      \n",
    "            probs  = torch.softmax(logits, dim=1)  \n",
    "            \n",
    "            # --- 레이블 정리 ---\n",
    "            if isinstance(y_batch, torch.Tensor):\n",
    "                y = y_batch.to(device)\n",
    "                if y.dim() > 1:\n",
    "                    y_list = y.argmax(dim=1).cpu().tolist()\n",
    "                else:\n",
    "                    y_list = y.cpu().tolist()\n",
    "            elif isinstance(y_batch, (list, tuple)):\n",
    "                y_list = list(y_batch)\n",
    "            else:\n",
    "                y_list = [int(y_batch)]\n",
    "            \n",
    "            all_true.extend(y_list)\n",
    "            \n",
    "            # defect 클래스 중 top-k=1 예측\n",
    "            top_probs, top_idx = probs[:, :defect_classes].max(dim=1)\n",
    "            all_pred.extend(top_idx.cpu().tolist())\n",
    "            all_prob.extend(top_probs.cpu().tolist())\n",
    "    \n",
    "    # --- 혼동행렬 만들기 ---\n",
    "    if thresholds:\n",
    "        cms = []\n",
    "        for thr in thresholds:\n",
    "            cm = [[0]*C for _ in range(C)]\n",
    "            for t, p, prob in zip(all_true, all_pred, all_prob):\n",
    "                pred_idx = p if prob > thr else (C-1)\n",
    "                cm[t][pred_idx] += 1\n",
    "            cms.append(cm)\n",
    "        return cms\n",
    "    else:\n",
    "        cm = [[0]*C for _ in range(C)]\n",
    "        for t, p in zip(all_true, all_pred):\n",
    "            cm[t][p] += 1\n",
    "        return cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a596ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classes_proportion_correctly_classified(c_matrix, failure_types):\n",
    "  dict_ = {}\n",
    "  for i in range(len(failure_types)):\n",
    "    dict_[failure_types[i]] = c_matrix[i][i]/np.sum(c_matrix[i])\n",
    "  \n",
    "  return dict_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd9c5e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_report(c_matrix):\n",
    "  precision = 0\n",
    "  recall = 0\n",
    "\n",
    "  num = 0\n",
    "  precision_den = 0\n",
    "  recall_den = 0\n",
    "\n",
    "  for i in range(len(c_matrix)):\n",
    "  # Index 8 is assumed to represent the negative class\n",
    "    if (i != 8):\n",
    "      num += c_matrix[i][i]\n",
    "      precision_den += c_matrix[i][i] + c_matrix[8][i]\n",
    "      recall_den += c_matrix[i][i] + c_matrix[i][8]\n",
    "    \n",
    "\n",
    "  precision = num/precision_den\n",
    "  recall = num/recall_den\n",
    "  return (\n",
    "      {'precision': precision, \n",
    "       'recall': recall,\n",
    "       'f1-measure': 2*(precision*recall)/(precision+recall)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f9772bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def roc_auc_report(confusion_matrixes):\n",
    "  tp_rates = []\n",
    "  fp_rates = []\n",
    "\n",
    "  for l in range(len(confusion_matrixes)):\n",
    "    tp = 0; fn = 0\n",
    "    fp = 0; tn = 0\n",
    "\n",
    "    cm = confusion_matrixes[l]\n",
    "\n",
    "    for i in range(len(cm)):\n",
    "      if (i != 8):\n",
    "        tp += cm[i][i] \n",
    "        fn += cm[i][8]\n",
    "        fp += cm[8][i]\n",
    "      \n",
    "      if (i == 8):\n",
    "        tn = cm[i][i]\n",
    "  \n",
    "    tp_rates.append(tp/(tp+fn))\n",
    "    fp_rates.append(fp/(fp+tn))\n",
    "\n",
    "  return (tp_rates, fp_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3ffe83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def roc_curve(tp_rates, fp_rates):\n",
    "  tp = copy.deepcopy(tp_rates)\n",
    "  #tp.extend([0])\n",
    "  tp.reverse()\n",
    "\n",
    "  fp = copy.deepcopy(fp_rates)\n",
    "  #fp.extend([0])\n",
    "  fp.reverse()\n",
    "\n",
    "  plt.plot(fp, tp)\n",
    "  plt.plot([0, 1], ls=\"--\")\n",
    "  plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n",
    "  plt.xlabel(\"false positive rate\") \n",
    "  plt.ylabel(\"true positive rate\")\n",
    "  plt.title(\"ROC curve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c4408c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "threshold1 = np.arange(0, 1, 0.01).tolist()\n",
    "threshold2 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87bf7869",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "val_dir        = 'C://Users/isang/OneDrive/Desktop/WM/data/WM811K_val'\n",
    "test_dir       = 'C://Users/isang/OneDrive/Desktop/WM/data/WM811K_test'\n",
    "train_aug_dir  = 'C://Users/isang/OneDrive/Desktop/WM/data/WM811K_train_aug'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((53, 52)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 4\n",
    "pin_memory = True\n",
    "\n",
    "\n",
    "val_dataset       = datasets.ImageFolder(val_dir,       \n",
    "                                         transform=transform)\n",
    "test_dataset      = datasets.ImageFolder(test_dir,      \n",
    "                                         transform=transform)\n",
    "train_aug_dataset = datasets.ImageFolder(train_aug_dir, \n",
    "                                         transform=transform)\n",
    "\n",
    "val_loader       = DataLoader(val_dataset,       \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,  \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=pin_memory)\n",
    "\n",
    "test_loader      = DataLoader(test_dataset,      \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,  \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=pin_memory)\n",
    "\n",
    "train_aug_loader = DataLoader(train_aug_dataset, \n",
    "                              batch_size=batch_size, \n",
    "                              shuffle=True,  \n",
    "                              num_workers=num_workers, \n",
    "                              pin_memory=pin_memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5845d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "class Model7(nn.Module):\n",
    "    def __init__(self, num_classes=9):\n",
    "        super(Model7, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),\n",
    "\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.AdaptiveMaxPool2d((1, 1))\n",
    "            )\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.classifier = nn.Linear(64, num_classes)\n",
    "        \n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f735a8",
   "metadata": {},
   "source": [
    "## Test Set Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2fbb66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0824  Test Acc: 0.9749\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model7 = Model7(num_classes=9)\n",
    "\n",
    "\n",
    "checkpointpath = \"C://Users/isang/OneDrive/Desktop/WM/models/model7.pth\"\n",
    "state = torch.load(checkpointpath, map_location=device)\n",
    "model7.load_state_dict(state)\n",
    "\n",
    "model7.to(device)\n",
    "model7.eval()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "test_loss = 0.0\n",
    "test_corrects = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        logits = model7(imgs)\n",
    "        loss = criterion(logits, labels)\n",
    "\n",
    "        bs = imgs.size(0)\n",
    "        test_loss += loss.item() * bs\n",
    "        preds = logits.argmax(dim=1)\n",
    "        test_corrects += (preds == labels).sum().item()\n",
    "        test_total += bs\n",
    "\n",
    "epoch_test_loss = test_loss / test_total\n",
    "epoch_test_acc = test_corrects / test_total\n",
    "\n",
    "print(f'Test Loss: {epoch_test_loss:.4f}  Test Acc: {epoch_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ffb44ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Center': 0.9509345794392523, 'Donut': 0.8558558558558559, 'Edge-Loc': 0.9057539682539683, 'Edge-Ring': 0.989648033126294, 'Loc': 0.8349928876244666, 'Near-full': 0.9333333333333333, 'Random': 0.8953488372093024, 'Scratch': 0.8232758620689655, 'none': 0.0}\n",
      "Mean Proportion : 0.7987937063234932\n"
     ]
    }
   ],
   "source": [
    "failure_types = [\"Center\", \"Donut\", \"Edge-Loc\", \"Edge-Ring\", \"Loc\", \"Near-full\", \"Random\", \"Scratch\", \"none\"]\n",
    "\n",
    "test_tuple = from_DataBatch_to_list(test_dataset)\n",
    "\n",
    "cm2 = confusion_matrix(model7, failure_types, test_tuple, threshold2)\n",
    "p = classes_proportion_correctly_classified(cm2, failure_types)\n",
    "\n",
    "print(p)\n",
    "\n",
    "print(f\"Mean Proportion : {np.mean(list(p.values()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874ab7bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
